# Redis
keys *
get node:chrstdan:ip
get node:chrstdan:info


ssh -p 16678 daniel@0.tcp.ap.ngrok.io \
  -L 10001:localhost:10001 \
  -L 8265:localhost:8265 \
  -L 6379:localhost:6379 \
  -L 8002:localhost:8002 \
  -L 5001:localhost:5001


ssh -p 16678 daniel@0.tcp.ap.ngrok.io \
  -L 5000:localhost:5000

helm list -A

kubectl delete pvc hub-db-dir -n jhub
kubectl delete pvc jupyterhub-pvc -n jhub
kubectl delete pv jupyterhub-pv-worker2

kubectl apply -f manifests/pvc.yaml

kubectl delete pod -n jhub -l component=hub
kubectl delete pod -n jhub -l component=proxy

curl -sfL https://get.k3s.io | K3S_URL=https://192.168.122.1:6443 K3S_TOKEN=K10f4b46cefdecc4364cfe539d2a45026a1f620d5fdfa352a9534d47aaa1be75ce7::server:7f44557fccb9a573a98069fd89eee8c3 sh -


start ray --head --port=6379 --dashboard-host=0.0.0.0 \
  --ray-client-server-port=10001



helm upgrade --install jhub jupyterhub/jupyterhub \
  --version=4.0.0 \
  --namespace jhub \
  --create-namespace \
  -f values.yaml


helm upgrade --cleanup-on-fail \
	--install jhub jupyterhub/jupyterhub \
	--namespace jhub \
	--version=4.0.0\
	--values /home/daniel/k3s-ray-jupyterlab/infra/kubernetes/jupyterlab/values.yaml \



helm upgrade --cleanup-on-fail \
	--install jhub jupyterhub/jupyterhub \
	--namespace jhub \
	--version=4.0.0 \
	--values values.yaml


helm upgrade --cleanup-on-fail \
  --install jupyterhub jupyterhub/jupyterhub \
  --namespace jh \
  --create-namespace \
  --version=4.0.0 \
  --values config.yaml


kubectl exec -n jhub proxy-bcd64c689-sch9m -- curl -v http://10.43.23.167:8081/hub/health


hub:
  config:
    JupyterHub:
      authenticator_class: dummy
      shutdown_on_logout: true
      bind_url: http://0.0.0.0:8081
    KubeSpawner:
      k8s_api_request_timeout: 60
      start_timeout: 300
      http_timeout: 300
    Authenticator:
      admin_users:
        - admin
    ConfigurableHTTPProxy:
      api_url: http://192.168.122.52:8001
  extraEnv:
    CONFIGPROXY_AUTH_TOKEN: "c413fe27d65c5916b7cf4028bf49a19b3056d59f2c2d1e79349244a6f758babe"
    JUPYTERHUB_PROXY_API_URL: http://192.168.122.52:8001
    JUPYTERHUB_LOG_LEVEL: DEBUG
  nodeSelector:
    kubernetes.io/hostname: rpl-worker-2
  db:
    url: sqlite:////data/jupyterhub.sqlite
  extraVolumes:
    - name: jupyterhub-db
      persistentVolumeClaim:
        claimName: jupyterhub-pvc
  extraVolumeMounts:
    - name: jupyterhub-db
      mountPath: /data
  resources:
    requests:
      memory: "3Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "2"
  livenessProbe:
    httpGet:
      path: /hub/health
      port: 8081
    initialDelaySeconds: 240
    periodSeconds: 20
    timeoutSeconds: 5
    failureThreshold: 10
  readinessProbe:
    httpGet:
      path: /hub/health
      port: 8081
    initialDelaySeconds: 120
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
  networkPolicy:
    enabled: false

proxy:
  secretToken: "c413fe27d65c5916b7cf4028bf49a19b3056d59f2c2d1e79349244a6f758babe"
  https:
    enabled: false
  service:
    type: ClusterIP
  chp:
    extraCommandLineFlags:
      - --port=8000
      - --api-port=8001
    extraEnv:
      CONFIGPROXY_API_PORT: "8001"
    extraPodSpec:
      hostNetwork: true
    nodeSelector:
      kubernetes.io/hostname: rpl-worker-2
    resources:
      requests:
        memory: "256Mi"
        cpu: "0.2"
      limits:
        memory: "512Mi"
        cpu: "0.5"

scheduling:
  userScheduler:
    enabled: true
    nodeSelector:
      kubernetes.io/hostname: rpl-worker-2

singleuser:
  defaultUrl: "/lab"
  storage:
    capacity: 1Gi
    dynamic:
      pvcNameTemplate: claim-{username}
      storageAccessModes: ["ReadWriteOnce"]
  memory:
    guarantee: 512Mi
    limit: 1Gi
  cpu:
    guarantee: 0.5
    limit: 1
  profileList:
    - display_name: "CPU Server"
      description: "Node worker biasa"
      kubespawner_override:
        image: danielcristh0/jupyterlab:1.1
        cpu_limit: 1
        mem_limit: 1G
        node_selector:
          kubernetes.io/hostname: rpl-worker-2
    - display_name: "GPU Server"
      description: "Jalankan di node head dengan GPU"
      kubespawner_override:
        image: danielcristh0/jupyterlab:1.1
        cpu_limit: 2
        mem_limit: 3G
        extra_resource_limits:
          nvidia.com/gpu: "1"
        node_selector:
          kubernetes.io/hostname: rpl

prePuller:
  hook:
    enabled: false
  continuous:
    enabled: false

cull:
  enabled: true
  timeout: 1800
  every: 60
  maxAge: 0
  users: false
  removeNamedServers: false

debug:
  enabled: true





















hub:
  config:
    JupyterHub:
      authenticator_class: dummy
      shutdown_on_logout: true
      bind_url: http://0.0.0.0:8081
      hub_connect_ip:  10.43.23.167
    KubeSpawner:
      k8s_api_request_timeout: 60
      start_timeout: 300
      http_timeout: 300
    Authenticator:
      admin_users:
        - admin
    ConfigurableHTTPProxy:
      api_url: http://192.168.122.52:8001
  extraEnv:
    CONFIGPROXY_AUTH_TOKEN: "c413fe27d65c5916b7cf4028bf49a19b3056d59f2c2d1e79349244a6f758babe"
    JUPYTERHUB_LOG_LEVEL: DEBUG
  nodeSelector:
    kubernetes.io/hostname: rpl-worker-2
  db:
    url: sqlite:////data/jupyterhub.sqlite
  extraVolumes:
    - name: jupyterhub-db
      persistentVolumeClaim:
        claimName: jupyterhub-pvc
  extraVolumeMounts:
    - name: jupyterhub-db
      mountPath: /data
  resources:
    requests:
      memory: "3Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "2"
  livenessProbe:
    httpGet:
      path: /hub/health
      port: 8081
    initialDelaySeconds: 240
    periodSeconds: 20
    timeoutSeconds: 5
    failureThreshold: 10
  readinessProbe:
    httpGet:
      path: /hub/health
      port: 8081
    initialDelaySeconds: 120
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
  networkPolicy:
    enabled: false

proxy:
  secretToken: "c413fe27d65c5916b7cf4028bf49a19b3056d59f2c2d1e79349244a6f758babe"
  https:
    enabled: false
  service:
    type: ClusterIP
  chp:
    extraCommandLineFlags:
      - --port=8000
      - --api-port=8001
    extraEnv:
      CONFIGPROXY_API_PORT: "8001"
    extraPodSpec:
      hostNetwork: true
    nodeSelector:
      kubernetes.io/hostname: rpl-worker-2
    resources:
      requests:
        memory: "256Mi"
        cpu: "0.2"
      limits:
        memory: "512Mi"
        cpu: "0.5"

scheduling:
  userScheduler:
    enabled: true
    nodeSelector:
      kubernetes.io/hostname: rpl-worker-2

singleuser:
  defaultUrl: "/lab"
  storage:
    capacity: 1Gi
    dynamic:
      pvcNameTemplate: claim-{username}
      storageAccessModes: ["ReadWriteOnce"]
  memory:
    guarantee: 512Mi
    limit: 1Gi
  cpu:
    guarantee: 0.5
    limit: 1
  profileList:
    - display_name: "CPU Server"
      description: "Node worker biasa"
      kubespawner_override:
        image: danielcristh0/jupyterlab:1.1
        cpu_limit: 1
        mem_limit: 1G
        node_selector:
          kubernetes.io/hostname: rpl-worker-2
    - display_name: "GPU Server"
      description: "Jalankan di node head dengan GPU"
      kubespawner_override:
        image: danielcristh0/jupyterlab:1.1
        cpu_limit: 2
        mem_limit: 3G
        extra_resource_limits:
          nvidia.com/gpu: "1"
        node_selector:
          kubernetes.io/hostname: rpl

prePuller:
  hook:
    enabled: false
  continuous:
    enabled: false

cull:
  enabled: true
  timeout: 1800
  every: 60
  maxAge: 0
  users: false
  removeNamedServers: false

debug:
  enabled: true

